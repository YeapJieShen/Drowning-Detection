{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "https://jati.sites.apiit.edu.my/files/2024/07/Volume8_Issue3_Paper7_2024_pp44-51.pdf  \n",
    "https://www.researchgate.net/publication/376683227_Drowning_Detection_System "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:05<00:00, 952kB/s] \n"
     ]
    }
   ],
   "source": [
    "# Path to the directory containing images\n",
    "image_dir = r\"C:\\Users\\hp\\OneDrive\\Documents\\Degree\\BMCS2133 Image Processing\\Drowning-Detection\\data\\images\\train\"  \n",
    "\n",
    "# Get all image files (JPEG, PNG, etc.)\n",
    "image_files = glob.glob(os.path.join(image_dir, \"*.*\"))  # Reads all file types\n",
    "\n",
    "# YOLOv11 model\n",
    "model = YOLO('yolo11n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 158.5ms\n",
      "Speed: 5.4ms preprocess, 158.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 151.2ms\n",
      "Speed: 2.4ms preprocess, 151.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 137.7ms\n",
      "Speed: 5.1ms preprocess, 137.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 147.3ms\n",
      "Speed: 3.7ms preprocess, 147.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 155.7ms\n",
      "Speed: 7.6ms preprocess, 155.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Loop through each image file\n",
    "for img_path in image_files:\n",
    "    # Read the image\n",
    "    image = cv2.imread(img_path)\n",
    "\n",
    "    # Check if the image is loaded correctly\n",
    "    if image is None:\n",
    "        print(f\"Failed to load: {img_path}\")\n",
    "        continue\n",
    "\n",
    "    # Resize the image to 800x600\n",
    "    smaller_image = cv2.resize(image, (800, 600))\n",
    "\n",
    "    # Convert the image to HSV color space\n",
    "    # hsv_image = cv2.cvtColor(smaller_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Perform object detection\n",
    "    results = model(smaller_image)\n",
    "\n",
    "    # Display bounding box if human is detected\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            if box.cls == 0:\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                cv2.rectangle(smaller_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 0), 2)\n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow(\"Image Viewer\", smaller_image)\n",
    "    \n",
    "    # Wait for a key press, press any key to show the next image\n",
    "    key = cv2.waitKey(0)  \n",
    "\n",
    "    # If 'q' is pressed, break the loop and exit\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
