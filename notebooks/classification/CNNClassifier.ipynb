{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97d7eab",
   "metadata": {},
   "source": [
    "# Detection with CNNClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f78dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Last Updated**: 2025-04-19 04:04:08\n",
       "\n",
       "**Python Version**: 3.11.11  \n",
       "**OS**: Windows 10.0.26100  \n",
       "**Architecture**: 64bit  \n",
       "**Hostname**: ShenLaptop  \n",
       "**Processor**: Intel64 Family 6 Model 186 Stepping 3, GenuineIntel  \n",
       "**RAM Size**: 15.65 GB  \n",
       "  \n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.getenv('SRC_DIR'))\n",
    "\n",
    "from utils.system import display_system_info\n",
    "\n",
    "display_system_info(markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a54e8904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "IDX_TO_CLASS = {\n",
    "    0: 'swimming',\n",
    "    1: 'treadwater',\n",
    "    2: 'drowning'\n",
    "}\n",
    "\n",
    "def xywhn_to_xyxy(image, x_n, y_n, w_n, h_n):\n",
    "    # cv2 images in HWC\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    x1 = int((x_n - w_n / 2) * width)\n",
    "    y1 = int((y_n - h_n / 2) * height)\n",
    "    x2 = int((x_n + w_n / 2) * width)\n",
    "    y2 = int((y_n + h_n / 2) * height)\n",
    "\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def cop_save_roi(images_folder, labels_folder, output_folder, idx_to_class):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for class_id, class_name in idx_to_class.items():\n",
    "        os.makedirs(os.path.join(output_folder, class_name), exist_ok=True)\n",
    "        \n",
    "    class_counters = {class_id: 0 for class_id in idx_to_class.keys()}\n",
    "\n",
    "    for image_file in os.listdir(images_folder):\n",
    "        if image_file.endswith('.jpg'):\n",
    "            base_name = os.path.splitext(image_file)[0]\n",
    "            \n",
    "            label_file = os.path.join(labels_folder, f\"{base_name}.txt\")\n",
    "            image_path = os.path.join(images_folder, image_file)\n",
    "            \n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            # Read the label file\n",
    "            with open(label_file, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "            \n",
    "            # Loop through each line in the label file\n",
    "            for line in lines:\n",
    "                values = line.strip().split()\n",
    "                class_id = int(values[0])\n",
    "                x_n, y_n, w_n, h_n = map(float, values[1:])\n",
    "\n",
    "                x1, y1, x2, y2 = xywhn_to_xyxy(image, x_n, y_n, w_n, h_n)\n",
    "\n",
    "                roi = image[y1:y2, x1:x2]\n",
    "\n",
    "                cv2.imwrite(os.path.join(output_folder, idx_to_class[class_id], f\"{str(class_counters[class_id]).zfill(6)}.jpg\"), roi)\n",
    "\n",
    "                class_counters[class_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8135f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'val']:\n",
    "    images_folder = os.path.join(os.getenv('RAW_DATA_DIR'), 'images', split)\n",
    "    labels_folder = os.path.join(os.getenv('RAW_DATA_DIR'), 'labels', split)\n",
    "    output_folder = os.path.join(os.getenv('ROI_DATA_DIR'), split)\n",
    "\n",
    "    cop_save_roi(images_folder, labels_folder, output_folder, IDX_TO_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7733b435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model created: CNNClassifier(\n",
      "  (features): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (3): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=16384, out_features=512, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from classify import TorchClassifier\n",
    "\n",
    "model_config = {\n",
    "    'num_classes': 3,\n",
    "    'num_blocks': 4,\n",
    "    'first_out_channel': 32,\n",
    "    'out_channel_multiplier': 2,\n",
    "    'kernel_size': 3,\n",
    "    'stride': 1,\n",
    "    'padding': 1,\n",
    "    'input_shape': (3, 128, 128)\n",
    "}\n",
    "\n",
    "model = TorchClassifier(model='CNNClassifier', config=model_config, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea60eb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Epoch       Loss   Accuracy    Macro(P          R        F1) Weighted(P          R        F1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5       1.26      35.33     0.3644     0.3736     0.3638     0.3644     0.3736     0.3638: 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 1.093: 100%|██████████| 37/37 [00:14<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    drowning     0.1573    1.0000    0.2718       182\n",
      "    swimming     0.0000    0.0000    0.0000       690\n",
      "  treadwater     0.0000    0.0000    0.0000       285\n",
      "\n",
      "    accuracy                         0.1573      1157\n",
      "   macro avg     0.0524    0.3333    0.0906      1157\n",
      "weighted avg     0.0247    0.1573    0.0428      1157\n",
      "\n",
      "      Epoch       Loss   Accuracy    Macro(P          R        F1) Weighted(P          R        F1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5     0.8506      55.43     0.6149     0.5862     0.5841     0.6149     0.5862     0.5841: 100%|██████████| 6/6 [00:06<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 1.203: 100%|██████████| 37/37 [00:15<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    drowning     0.1573    1.0000    0.2718       182\n",
      "    swimming     0.0000    0.0000    0.0000       690\n",
      "  treadwater     0.0000    0.0000    0.0000       285\n",
      "\n",
      "    accuracy                         0.1573      1157\n",
      "   macro avg     0.0524    0.3333    0.0906      1157\n",
      "weighted avg     0.0247    0.1573    0.0428      1157\n",
      "\n",
      "      Epoch       Loss   Accuracy    Macro(P          R        F1) Weighted(P          R        F1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5     0.7105      65.22     0.6946     0.6897     0.6836     0.6946     0.6897     0.6836: 100%|██████████| 6/6 [00:06<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 1.139: 100%|██████████| 37/37 [00:14<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    drowning     0.1573    1.0000    0.2718       182\n",
      "    swimming     0.0000    0.0000    0.0000       690\n",
      "  treadwater     0.0000    0.0000    0.0000       285\n",
      "\n",
      "    accuracy                         0.1573      1157\n",
      "   macro avg     0.0524    0.3333    0.0906      1157\n",
      "weighted avg     0.0247    0.1573    0.0428      1157\n",
      "\n",
      "      Epoch       Loss   Accuracy    Macro(P          R        F1) Weighted(P          R        F1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5     0.4959      76.63     0.8149     0.8103     0.8108     0.8149     0.8103     0.8108: 100%|██████████| 6/6 [00:06<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 1.238: 100%|██████████| 37/37 [00:14<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    drowning     0.1573    1.0000    0.2718       182\n",
      "    swimming     0.0000    0.0000    0.0000       690\n",
      "  treadwater     0.0000    0.0000    0.0000       285\n",
      "\n",
      "    accuracy                         0.1573      1157\n",
      "   macro avg     0.0524    0.3333    0.0906      1157\n",
      "weighted avg     0.0247    0.1573    0.0428      1157\n",
      "\n",
      "      Epoch       Loss   Accuracy    Macro(P          R        F1) Weighted(P          R        F1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      0.489      73.91     0.7819     0.7816     0.7816     0.7819     0.7816     0.7816: 100%|██████████| 6/6 [00:06<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 1.218: 100%|██████████| 37/37 [00:15<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    drowning     0.1576    1.0000    0.2723       182\n",
      "    swimming     1.0000    0.0029    0.0058       690\n",
      "  treadwater     0.0000    0.0000    0.0000       285\n",
      "\n",
      "    accuracy                         0.1590      1157\n",
      "   macro avg     0.3859    0.3343    0.0927      1157\n",
      "weighted avg     0.6212    0.1590    0.0463      1157\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class RandomAffineWithInpainting:\n",
    "    def __init__(self, degrees=0, translate=(0.2, 0.2), radius=3):\n",
    "        self.affine = transforms.RandomAffine(degrees=degrees, translate=translate)\n",
    "        self.inpaint_radius = radius\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Step 1: Apply affine transform (returns PIL image)\n",
    "        img = self.affine(img)\n",
    "\n",
    "        # Step 2: Convert to NumPy array\n",
    "        img_np = np.array(img)\n",
    "\n",
    "        # return Image.fromarray(img_np)\n",
    "\n",
    "        # Step 3: Create mask where pixels are black\n",
    "        gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "        mask = cv2.inRange(gray, 0, 1)\n",
    "\n",
    "        # Step 4: Inpaint using OpenCV\n",
    "        inpainted_np = cv2.inpaint(img_np, mask, self.inpaint_radius, cv2.INPAINT_TELEA)\n",
    "\n",
    "        # Step 5: Convert back to PIL\n",
    "        img_inpainted = Image.fromarray(inpainted_np)\n",
    "\n",
    "        return img_inpainted\n",
    "\n",
    "class CustomTransformation(object):\n",
    "    def __call__(self, img):\n",
    "        # Ensure the image is in PIL format before converting\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = transforms.ToPILImage()(img)  # Convert tensor to PIL image\n",
    "        \n",
    "        # Convert the image to HSV using PIL\n",
    "        img_hsv = np.array(img.convert(\"RGB\"))  # Convert to numpy array (RGB)\n",
    "        img_hsv = cv2.cvtColor(img_hsv, cv2.COLOR_RGB2HSV)  # Convert to HSV\n",
    "        \n",
    "        # Split the HSV image into H, S, and V channels\n",
    "        h, s, v = cv2.split(img_hsv)\n",
    "        \n",
    "        # Apply average blurring to the V channel\n",
    "        v_blurred = cv2.blur(v, (7, 7))  # Apply 3x3 average blur to the V channel\n",
    "        \n",
    "        # Merge the H, S, and blurred V channels back together\n",
    "        img_hsv_blurred = cv2.merge([h, s, v_blurred])\n",
    "        \n",
    "        # Convert the image back to PIL format\n",
    "        return Image.fromarray(img_hsv_blurred)\n",
    "\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    RandomAffineWithInpainting(degrees=0, translate=(0.2, 0.2))\n",
    "])\n",
    "\n",
    "enhance_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    CustomTransformation(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "results = model.train(\n",
    "    data_path=os.getenv('ROI_DATA_DIR'),\n",
    "    imbalance=True,\n",
    "    fraction=0.01,\n",
    "    val_test_ratio=0.5,\n",
    "    input_size=128,\n",
    "    optimizer='Adam',\n",
    "    lr=1e-4,\n",
    "    aug_transform=aug_transform,\n",
    "    enhance_transform=enhance_transform,\n",
    "    val_transform=val_transform,\n",
    "    batch_size=32,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a53d840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:\\Users\\hp\\Downloads\\Drowning-Detection\\models\\CNN\\test.pt\n"
     ]
    }
   ],
   "source": [
    "model.save(\n",
    "    os.path.join(os.getenv('CNN_MODEL_DIR'), 'test.pt')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef083eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add model prediction here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
