{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce296cdb",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "This project utilizes the [**Drowning Detection Dataset**](https://github.com/Wang-Kaikai/drowning-detection-dataset) sourced from the open-access repository provided by Wang Kaikai et al.\n",
    "\n",
    "This dataset was originally introduced in their research paper:\n",
    "[**A Dataset for Drowning Detection Based on Surveillance Videos**](https://doi.org/10.3390/app14010200)\n",
    "\n",
    "The dataset consists of labeled surveillance video clips that represent various human states in aquatic environments, including:\n",
    "\n",
    "- **Drowning**\n",
    "- **Treading Water**\n",
    "- **Swimming**\n",
    "\n",
    "In this section, we aim to perform a thorough exploratory data analysis (EDA) to understand:\n",
    "\n",
    "- The class distribution across different video segments.\n",
    "- Sample visualizations for each behavior class.\n",
    "\n",
    "This analysis serves as a foundation for designing robust detection and classification models in the later stages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10004b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Last Updated**: 2025-04-17 04:10:07\n",
       "\n",
       "**Python Version**: 3.11.11  \n",
       "**OS**: Windows 10.0.26100  \n",
       "**Architecture**: 64bit  \n",
       "**Hostname**: ShenLaptop  \n",
       "**Processor**: Intel64 Family 6 Model 186 Stepping 3, GenuineIntel  \n",
       "**RAM Size**: 15.65 GB  \n",
       "  \n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.getenv('SRC_DIR'))\n",
    "\n",
    "from utils.system import display_system_info\n",
    "\n",
    "display_system_info(markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdfdd12",
   "metadata": {},
   "source": [
    "According to the paper by [Wang KaiKai et al.](https://doi.org/10.3390/app14010200), the label numbers are corresponding to the class labels as follows:\n",
    "\n",
    "| Label Number | Class Name  |\n",
    "|--------------|-------------|\n",
    "| 0            | Swimming    |\n",
    "| 1            | Treading Water |\n",
    "| 2            | Drowning    |\n",
    "\n",
    "## Class Label Distribution\n",
    "\n",
    "Here we check the number of instances in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705cc8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aebcc44a",
   "metadata": {},
   "source": [
    "## Sample Image Visualisation\n",
    "\n",
    "This section provides a visual overview of sample frames extracted from the drowning detection dataset. Each image is annotated with bounding boxes indicating detected individuals, which correspond to different classes, that is *swimming*, *treading water*, and *drowning*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46dedc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07d093a8",
   "metadata": {},
   "source": [
    "## Sample ROI for Classes\n",
    "\n",
    "Here we display some sample cropped images for each class\n",
    "\n",
    "Therefore, we can further confirm that the class labels are as follows:\n",
    "\n",
    "| Label Number | Class Name  |\n",
    "|--------------|-------------|\n",
    "| 0            | Swimming    |\n",
    "| 1            | Treading Water |\n",
    "| 2            | Drowning    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb81d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "917553d6",
   "metadata": {},
   "source": [
    "## Understanding Image Channels\n",
    "\n",
    "To better understand how different color representations impact image perception and feature extraction, we visualize the individual channel components across various color spaces:\n",
    "\n",
    "- **RGB**: Red, Green, Blue  \n",
    "- **HSV**: Hue, Saturation, Value  \n",
    "- **LAB**: Lightness, A (green–red), B (blue–yellow)  \n",
    "\n",
    "By visualizing these channels independently, we can observe how each component contributes to the image, aiding in preprocessing and model interpretation tasks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
