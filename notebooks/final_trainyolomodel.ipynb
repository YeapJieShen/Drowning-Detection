{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train YOLO Model for Human Detection",
   "id": "f6dc85e42776f8f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T13:05:19.326145Z",
     "start_time": "2025-04-18T13:05:19.311487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "from ultralytics import YOLO"
   ],
   "id": "d86746c38fbec31d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T13:05:19.908501Z",
     "start_time": "2025-04-18T13:05:19.901067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if CUDA gpu is available\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ],
   "id": "740332de1da083b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T13:05:20.416169Z",
     "start_time": "2025-04-18T13:05:20.410844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Project file paths\n",
    "notebook_dir = os.getcwd()  # Current directory (notebooks)\n",
    "project_root = os.path.dirname(notebook_dir)  # go up one level to get project root\n",
    "data_dir = os.path.join(project_root, \"data\")\n",
    "image_dir = os.path.join(data_dir, \"images\")\n",
    "label_dir = os.path.join(data_dir, \"labels\")\n",
    "model_dir = os.path.join(project_root, \"models\")\n",
    "temp_label_dir = os.path.join(data_dir, \"temp_labels\")\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Model directory: {model_dir}\")\n",
    "print(f\"Temporary labels directory: {temp_label_dir}\")"
   ],
   "id": "a0f790f39ece90dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\n",
      "Data directory: C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\data\n",
      "Model directory: C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\models\n",
      "Temporary labels directory: C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\data\\temp_labels\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Prepare data for YOLO training",
   "id": "52b04e014dbf9752"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T13:05:33.058036Z",
     "start_time": "2025-04-18T13:05:24.714512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create temporary labels directory for unified class\n",
    "def create_temp_labels():\n",
    "    # Create temp directories\n",
    "    os.makedirs(os.path.join(temp_label_dir, \"train\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(temp_label_dir, \"val\"), exist_ok=True)\n",
    "\n",
    "    # Process train labels\n",
    "    train_labels = os.path.join(label_dir, \"train\")\n",
    "    for label_file in os.listdir(train_labels):\n",
    "        if label_file.endswith(\".txt\"):\n",
    "            input_path = os.path.join(train_labels, label_file)\n",
    "            output_path = os.path.join(temp_label_dir, \"train\", label_file)\n",
    "\n",
    "            with open(input_path, 'r') as infile:\n",
    "                lines = infile.readlines()\n",
    "\n",
    "            with open(output_path, 'w') as outfile:\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        # Change class id to 0, keep other values the same\n",
    "                        new_line = f\"0 {' '.join(parts[1:])}\\n\"\n",
    "                        outfile.write(new_line)\n",
    "\n",
    "    # Process validation labels\n",
    "    val_labels = os.path.join(label_dir, \"val\")\n",
    "    for label_file in os.listdir(val_labels):\n",
    "        if label_file.endswith(\".txt\"):\n",
    "            input_path = os.path.join(val_labels, label_file)\n",
    "            output_path = os.path.join(temp_label_dir, \"val\", label_file)\n",
    "\n",
    "            with open(input_path, 'r') as infile:\n",
    "                lines = infile.readlines()\n",
    "\n",
    "            with open(output_path, 'w') as outfile:\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        # Change class id to 0, keep other values the same\n",
    "                        new_line = f\"0 {' '.join(parts[1:])}\\n\"\n",
    "                        outfile.write(new_line)\n",
    "\n",
    "    print(f\"Created temporary labels with unified class at {temp_label_dir}\")\n",
    "\n",
    "# Temporarily swap label folders\n",
    "def swap_labels_for_training():\n",
    "    backup_labels_dir = os.path.join(data_dir, \"labels_backup\")\n",
    "    if os.path.exists(backup_labels_dir):\n",
    "        shutil.rmtree(backup_labels_dir)\n",
    "    shutil.move(label_dir, backup_labels_dir)\n",
    "    shutil.copytree(temp_label_dir, label_dir)\n",
    "    print(\"Swapped original labels with temporary labels for training.\")\n",
    "    return backup_labels_dir\n",
    "\n",
    "# Restore original label folder after training\n",
    "def restore_labels(backup_labels_dir):\n",
    "    if os.path.exists(label_dir):\n",
    "        shutil.rmtree(label_dir)\n",
    "    shutil.move(backup_labels_dir, label_dir)\n",
    "    print(\"Restored original labels after training.\")\n",
    "\n",
    "def create_data_yaml():\n",
    "    yaml_content = f\"\"\"\n",
    "path: {data_dir}\n",
    "train: images/train\n",
    "val: images/val\n",
    "names:\n",
    "  0: human\n",
    "\"\"\"\n",
    "    yaml_path = os.path.join(data_dir, \"human_detection_data.yaml\")\n",
    "    with open(yaml_path, \"w\") as f:\n",
    "        f.write(yaml_content.strip())\n",
    "    print(f\"Created data configuration at {yaml_path}\")\n",
    "    return yaml_path\n",
    "\n",
    "# Create temporary labels and the data.yaml file\n",
    "create_temp_labels()\n",
    "data_yaml = create_data_yaml()\n",
    "backup_labels_path = swap_labels_for_training()  # Swap labels before training"
   ],
   "id": "c7930a10ced45728",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created temporary labels with unified class at C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\data\\temp_labels\n",
      "Created data configuration at C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\data\\human_detection_data.yaml\n",
      "Swapped original labels with temporary labels for training.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Train YOLO11 Model",
   "id": "21e5fb28e3f167ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T13:05:40.151482Z",
     "start_time": "2025-04-18T13:05:40.144410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_yolo_model(data_yaml, epochs=50, imgsz=640, batch_size=16):\n",
    "    print(\"Loading YOLO11s model...\")\n",
    "    model = YOLO(\"yolo11s.pt\")\n",
    "\n",
    "    print(f\"Training model for {epochs} epochs...\")\n",
    "    results = model.train(\n",
    "        data=data_yaml,\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        batch=batch_size,\n",
    "        device=0 if torch.cuda.is_available() else 'cpu',\n",
    "        project=model_dir,\n",
    "        name=\"human_detection\",\n",
    "        exist_ok=True,\n",
    "        # Data augmentation settings\n",
    "        hsv_v=0.4,     # Value (brightness) augmentation\n",
    "        degrees=10.0,  # Rotation augmentation\n",
    "        fliplr=0.5,    # Horizontal flip with 50% probability\n",
    "        scale=0.5,     # Random scaling\n",
    "        translate=0.1  # Translation augmentation\n",
    "    )\n",
    "\n",
    "    # Save the trained model\n",
    "    model_path = os.path.join(model_dir, \"human_detection_yolo11s.pt\")\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    return model, results"
   ],
   "id": "4074ad86efab0c1d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Validate Model",
   "id": "a950e668e8b12c3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T13:05:41.745924Z",
     "start_time": "2025-04-18T13:05:41.736474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_model(data_yaml, batch_size=4):\n",
    "    print(\"Loading best model for validation...\")\n",
    "    model = YOLO(os.path.join(model_dir, \"human_detection\", \"weights\", \"best.pt\"))  # Load best model\n",
    "\n",
    "    print(\"Validating model...\")\n",
    "    results = model.val(\n",
    "        data=data_yaml,\n",
    "        batch=batch_size,\n",
    "        device=0 if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "\n",
    "    # Print metrics\n",
    "    metrics = results.box\n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(f\"mAP50: {metrics.map50.mean():.4f}\")\n",
    "    print(f\"mAP50-95: {metrics.map.mean():.4f}\")\n",
    "    print(f\"Precision: {metrics.p.mean():.4f}\")\n",
    "    print(f\"Recall: {metrics.r.mean():.4f}\")\n",
    "\n",
    "    return results"
   ],
   "id": "2a7d7aee4cc05c62",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Run all steps",
   "id": "e6fd8ff09ebdf408"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T13:48:00.488084Z",
     "start_time": "2025-04-18T13:06:00.068072Z"
    }
   },
   "cell_type": "code",
   "source": "model, training_results = train_yolo_model(data_yaml, epochs=20)",
   "id": "9bb4f9cf51e91ee5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLO11s model...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt to 'yolo11s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18.4M/18.4M [00:04<00:00, 4.76MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for 20 epochs...\n",
      "New https://pypi.org/project/ultralytics/8.3.111 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.79  Python-3.12.3 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0mtask=detect, mode=train, model=yolo11s.pt, data=C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\data\\human_detection_data.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\models, name=human_detection, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=10.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\models\\human_detection\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,428,179 parameters, 9,428,163 gradients, 21.5 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\models\\human_detection', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 20.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\data\\labels\\train... 7000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 7000/7000 [00:02<00:00, 2488.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\data\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\data\\labels\\val... 1572 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1572/1572 [00:01<00:00, 838.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\data\\labels\\val.cache\n",
      "Plotting labels to C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\models\\human_detection\\labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001B[1mC:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\models\\human_detection\u001B[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      4.05G      1.492      1.398      1.233         20        640: 100%|██████████| 438/438 [01:53<00:00,  3.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:14<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.908      0.923      0.963      0.615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      4.06G      1.421     0.8074      1.195         21        640: 100%|██████████| 438/438 [01:47<00:00,  4.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317       0.55      0.785      0.524      0.307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      4.06G      1.384     0.7648       1.17         23        640: 100%|██████████| 438/438 [01:44<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317       0.94      0.976      0.987      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      4.03G      1.339     0.7086      1.153          9        640: 100%|██████████| 438/438 [01:43<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.977      0.981      0.989      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      4.05G      1.308     0.6742      1.135         25        640: 100%|██████████| 438/438 [01:43<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:12<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.981      0.984      0.993      0.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      4.04G      1.272     0.6395      1.112         24        640: 100%|██████████| 438/438 [01:43<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:12<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.985      0.984      0.993      0.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      4.06G      1.238     0.6165        1.1         19        640: 100%|██████████| 438/438 [01:43<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.985      0.985      0.993      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      4.04G       1.22     0.5927      1.089         29        640: 100%|██████████| 438/438 [01:43<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.981      0.987      0.994      0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      4.05G      1.193     0.5758      1.078         27        640: 100%|██████████| 438/438 [01:43<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:12<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.988      0.995      0.994      0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      4.05G      1.177     0.5554       1.07         17        640: 100%|██████████| 438/438 [01:43<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.983      0.994      0.993       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      4.07G      1.137     0.5145      1.069         12        640: 100%|██████████| 438/438 [01:43<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:12<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.984      0.992      0.993      0.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      4.04G      1.123     0.5082      1.061          8        640: 100%|██████████| 438/438 [01:43<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:12<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317       0.99      0.994      0.993      0.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      4.05G      1.108     0.4966      1.052         11        640: 100%|██████████| 438/438 [01:41<00:00,  4.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:12<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.988      0.995      0.994       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      4.05G      1.098     0.4871      1.041         11        640: 100%|██████████| 438/438 [01:41<00:00,  4.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:12<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.988      0.997      0.994      0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      4.06G      1.073     0.4742      1.033         14        640: 100%|██████████| 438/438 [01:42<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.989      0.997      0.994      0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      4.05G      1.059     0.4584      1.029         11        640: 100%|██████████| 438/438 [01:42<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.993      0.996      0.994      0.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      4.06G      1.032     0.4423      1.015         12        640: 100%|██████████| 438/438 [01:42<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.995      0.997      0.994      0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      4.05G      1.021     0.4324      1.008          8        640: 100%|██████████| 438/438 [01:42<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.991      0.997      0.994      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      4.06G     0.9981     0.4214     0.9995         11        640: 100%|██████████| 438/438 [01:42<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.991      0.998      0.994      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      4.05G     0.9912     0.4102      0.996         13        640: 100%|██████████| 438/438 [01:41<00:00,  4.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.994      0.997      0.994      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.666 hours.\n",
      "Optimizer stripped from C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\models\\human_detection\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\models\\human_detection\\weights\\best.pt, 19.2MB\n",
      "\n",
      "Validating C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\models\\human_detection\\weights\\best.pt...\n",
      "Ultralytics 8.3.79  Python-3.12.3 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1572       2317      0.991      0.997      0.994      0.778\n",
      "Speed: 0.2ms preprocess, 2.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001B[1mC:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\models\\human_detection\u001B[0m\n",
      "Model saved to C:\\Users\\jrom\\DataspellProjects\\Drowning-Detection\\models\\human_detection_yolo11s.pt\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "validation_results = validate_model(data_yaml)",
   "id": "f3d645fd6254e996"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
