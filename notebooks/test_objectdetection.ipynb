{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Object Detection using YOLOv11\n",
    "Using the pre-trained YOLOv11 model to detect people in images from the training dataset.\n",
    "<br/><br/>How it Works :\n",
    "1. Load the YOLOv11 model.\n",
    "2. Read images from the training dataset.\n",
    "3. Run the YOLO model on each image.\n",
    "4. Draw bounding boxes around detected people.\n",
    "5. Display the processed image.\n",
    "6. Exit on pressing 'q'."
   ],
   "id": "fdb1c3070f81ad1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T10:16:43.543938Z",
     "start_time": "2025-02-28T10:16:37.978906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import os"
   ],
   "id": "3b7d62d448e16cdc",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-28T10:27:19.807798Z",
     "start_time": "2025-02-28T10:27:15.314575Z"
    }
   },
   "source": [
    "# Define path to training images\n",
    "train_dir = \"../data/images/train\"\n",
    "\n",
    "# Load YOLOv11 model (pre-trained) - n/s/m/l/x are available\n",
    "model = YOLO(\"yolo11s.pt\")\n",
    "\n",
    "# Fixed display width for the resized image\n",
    "display_width = 800\n",
    "\n",
    "# Toggle grayscale conversion (grayscale seems to have worse performance)\n",
    "use_grayscale = False\n",
    "\n",
    "# Process images in the train folder\n",
    "for img_name in sorted(os.listdir(train_dir)):\n",
    "    img_path = os.path.join(train_dir, img_name)\n",
    "\n",
    "    # Read image\n",
    "    frame = cv2.imread(img_path)\n",
    "    if frame is None:\n",
    "        continue  # skip if image cannot be read\n",
    "\n",
    "    # Convert to grayscale if enabled\n",
    "    if use_grayscale:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)  # Convert back to 3 channels for YOLO\n",
    "\n",
    "    # Run YOLO detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            if int(box.cls[0]) == 0:  # Class 0 = \"person\" in YOLO\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Resize image for display while keeping aspect ratio\n",
    "    height, width = frame.shape[:2]\n",
    "    new_height = int((display_width / width) * height)  # Maintain aspect ratio\n",
    "    frame_resized = cv2.resize(frame, (display_width, new_height))\n",
    "\n",
    "    # Show the processed image\n",
    "    cv2.imshow(\"Drowning Detection\", frame_resized)\n",
    "\n",
    "    # Wait for 1ms and exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 surfboard, 81.7ms\n",
      "Speed: 2.5ms preprocess, 81.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 92.4ms\n",
      "Speed: 2.1ms preprocess, 92.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 86.2ms\n",
      "Speed: 2.3ms preprocess, 86.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 surfboard, 99.7ms\n",
      "Speed: 1.7ms preprocess, 99.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 85.2ms\n",
      "Speed: 2.0ms preprocess, 85.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 82.4ms\n",
      "Speed: 1.9ms preprocess, 82.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 surfboard, 87.3ms\n",
      "Speed: 2.1ms preprocess, 87.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 85.7ms\n",
      "Speed: 1.8ms preprocess, 85.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.4ms\n",
      "Speed: 1.6ms preprocess, 82.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 84.0ms\n",
      "Speed: 1.7ms preprocess, 84.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.9ms\n",
      "Speed: 2.4ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 chair, 80.6ms\n",
      "Speed: 1.5ms preprocess, 80.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.6ms\n",
      "Speed: 2.0ms preprocess, 80.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 dog, 1 chair, 118.6ms\n",
      "Speed: 2.1ms preprocess, 118.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 surfboard, 1 chair, 77.8ms\n",
      "Speed: 1.4ms preprocess, 77.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 76.4ms\n",
      "Speed: 2.0ms preprocess, 76.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 77.1ms\n",
      "Speed: 1.9ms preprocess, 77.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 77.6ms\n",
      "Speed: 2.0ms preprocess, 77.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 70.2ms\n",
      "Speed: 2.2ms preprocess, 70.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 surfboard, 81.2ms\n",
      "Speed: 2.2ms preprocess, 81.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.3ms\n",
      "Speed: 1.7ms preprocess, 79.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 79.1ms\n",
      "Speed: 2.0ms preprocess, 79.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 78.4ms\n",
      "Speed: 1.7ms preprocess, 78.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 78.4ms\n",
      "Speed: 1.7ms preprocess, 78.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 78.7ms\n",
      "Speed: 1.8ms preprocess, 78.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 80.7ms\n",
      "Speed: 1.8ms preprocess, 80.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 79.4ms\n",
      "Speed: 1.8ms preprocess, 79.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.6ms\n",
      "Speed: 2.1ms preprocess, 81.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 surfboard, 81.7ms\n",
      "Speed: 1.8ms preprocess, 81.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.9ms\n",
      "Speed: 2.6ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 81.8ms\n",
      "Speed: 1.5ms preprocess, 81.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 75.3ms\n",
      "Speed: 1.9ms preprocess, 75.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 77.9ms\n",
      "Speed: 2.2ms preprocess, 77.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 chair, 73.3ms\n",
      "Speed: 2.2ms preprocess, 73.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Possible ways to Improve the Model\n",
    "1. Use a larger YOLO model\n",
    "2. Apply image preprocessing (enhance contrast, histogram equalisation)\n",
    "3. Adjust confidence threshold\n",
    "4. Apply frame resizing before detection"
   ],
   "id": "4c410056218cf050"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
